{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c1e2fc-c2f6-472b-821e-1e98d2dfa35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512aa954-c2b0-4639-bdc5-3402ccba4a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/trl.git@7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
      "  Cloning https://github.com/huggingface/trl.git (to revision 7630f877f91c556d9e5a3baa4b6e2894d90ff84c) to /tmp/pip-req-build-423s_or1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-423s_or1\n",
      "  Running command git rev-parse -q --verify 'sha^7630f877f91c556d9e5a3baa4b6e2894d90ff84c'\n",
      "  Running command git fetch -q https://github.com/huggingface/trl.git 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
      "  Running command git checkout -q 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
      "  Resolved https://github.com/huggingface/trl.git to commit 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from trl==0.7.12.dev0) (2.2.2)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from trl==0.7.12.dev0) (4.39.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from trl==0.7.12.dev0) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from trl==0.7.12.dev0) (0.28.0)\n",
      "Requirement already satisfied: datasets in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from trl==0.7.12.dev0) (2.18.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from trl==0.7.12.dev0) (0.7.3)\n",
      "Requirement already satisfied: filelock in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from torch>=1.4.0->trl==0.7.12.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl==0.7.12.dev0) (12.3.101)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.21.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (4.65.0)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (1.7.1)\n",
      "Requirement already satisfied: psutil in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from accelerate->trl==0.7.12.dev0) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets->trl==0.7.12.dev0) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets->trl==0.7.12.dev0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets->trl==0.7.12.dev0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets->trl==0.7.12.dev0) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets->trl==0.7.12.dev0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets->trl==0.7.12.dev0) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets->trl==0.7.12.dev0) (3.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.4.0->trl==0.7.12.dev0) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from pandas->datasets->trl==0.7.12.dev0) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from pandas->datasets->trl==0.7.12.dev0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from pandas->datasets->trl==0.7.12.dev0) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from sympy->torch>=1.4.0->trl==0.7.12.dev0) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.12.dev0) (1.16.0)\n",
      "Building wheels for collected packages: trl\n",
      "  Building wheel for trl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for trl: filename=trl-0.7.12.dev0-py3-none-any.whl size=173433 sha256=564d8661d811886747072049467655afaf0787b478a7a042cc4242136182af8a\n",
      "  Stored in directory: /home/anjaliraj/.cache/pip/wheels/c5/1f/a8/f095d94c19e2d43dee2cc7faa8a2e3b531da2034b39b6c788d\n",
      "Successfully built trl\n",
      "Installing collected packages: trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.7.11.dev0\n",
      "    Uninstalling trl-0.7.11.dev0:\n",
      "      Successfully uninstalled trl-0.7.11.dev0\n",
      "Successfully installed trl-0.7.12.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/trl.git@7630f877f91c556d9e5a3baa4b6e2894d90ff84c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f3e036-0089-45eb-82fc-f2acd7cf8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e676d903-90dd-4867-a627-87cd83cea21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfed4ef1-148a-436a-bb6a-be0cc66bbe32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes==0.41.3 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (0.41.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes==0.41.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232fa80c-b743-4bfe-aac7-290a6b13379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (0.21.3)\n",
      "Requirement already satisfied: packaging in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372f423a-9523-4db6-b958-0e7adc7c8d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (4.39.0.dev0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anjaliraj/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.39.0.dev0\n",
      "    Uninstalling transformers-4.39.0.dev0:\n",
      "      Successfully uninstalled transformers-4.39.0.dev0\n",
      "Successfully installed transformers-4.39.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd46e21b-d7ff-4063-8ba3-1388cdaf87c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 08:14:26.540103: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-13 08:14:26.602966: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 08:14:27.510965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2cabb98-4038-4ba9-a35f-5e3c8ab1b7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.2.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60feefc0-a1ac-4d67-a9ee-dce230b36372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"working on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a64cda5-7b84-4daf-ad5f-3ef60526bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/anjaliraj/Amit/BTP2/IMDB Dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24784211-ca78-4e13-9e19-f1d819fd4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename,encoding=\"utf-8\", encoding_errors=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be973eb0-8917-4b79-9311-eda81109993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Positive samples: 25000\n",
      "Number of Negative samples: 25000\n"
     ]
    }
   ],
   "source": [
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of Positive samples:\", sentiment_counts['positive'])\n",
    "print(\"Number of Negative samples:\", sentiment_counts['negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fa24fd4-f8ac-4d8a-9bb8-852c390bf885",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list()\n",
    "X_test = list()\n",
    "\n",
    "for sentiment in [\"positive\",\"negative\"]:\n",
    "    train,test = train_test_split(df[df.sentiment == sentiment],train_size = 500,test_size = 250,random_state = 42)\n",
    "    X_train.append(train)\n",
    "    X_test.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cf3e8e0-6550-43de-b8dd-5fc14b4d5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat(X_train).sample(frac=1, random_state=27)\n",
    "X_test = pd.concat(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75366920-a845-456b-a36b-2f575fc57a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_idx = [idx for idx in df.index if idx not in list(train.index) + list(test.index)]\n",
    "X_eval = df[df.index.isin(eval_idx)]\n",
    "X_eval = (X_eval.groupby('sentiment',group_keys = False).apply(lambda x:x.sample(n=250,random_state = 10,replace = True)))\n",
    "X_train = X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99d7bd4d-ecc0-43e8-9a51-bec8da999dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point[\"review\"]}] = {data_point[\"sentiment\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point[\"review\"]}] = \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c010f3e3-6464-4120-b41d-b5dd4522dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), \n",
    "                       columns=[\"review\"])\n",
    "X_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1), \n",
    "                      columns=[\"review\"])\n",
    "\n",
    "y_true = X_test.sentiment\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"review\"])\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0fe1ec4-1e19-464e-875a-ef779056fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_data['review']))\n",
    "len(eval_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2591024d-81e4-482b-bbae-c7aa32accf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analyze the sentiment of the news headline enclosed in square brackets, \\n            determine if it is positive, neutral, or negative, and return the answer as \\n            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\\n\\n            [If this is all the Watchowski\\'s have to offer in terms of a back story to the Matrix, than I really have to question the claims of all of the fans who believe that the movies are intended to register on a deeper level. The second renaissance, while visually stunning & beautiful is, story-wise cliched & ludicrous. How many times have we heard the story of humans relying too much on technology, humans all-too eager to make war, humans basically destroying themselves? There is nothing new here. And I have another question. Considering the plot of the second renaissance, doesn\\'t that make the machines the good guys?! The machines are oppressed for generations by their cruel human overmasters. They fight back, win their freedom and seek to establish a peaceful harmonious coexistence with the humans, who reject them in favor of all-out war, which the cleverer machines naturally win. If this is the back-story, then we shouldn\\'t be rooting for Neo, we should be rooting for the machines! The humans were cruel and oppressive, while the machines were courageous and attepted to be compassionate. Since I do not believe that the Watchowski\\'s intend for us to favor the machines over the humans, I have to believe that the Second Renaissance was simply a misguided attempt @ creating a back-story.] = negative'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "139b46b1-60fe-4473-8584-09d2398383a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe72838ea9134ea490364b1a63c4ae4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 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\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168904f2-e30b-461a-878d-99c27af45d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7fdf41-1c3f-4254-824e-ed1d3da6d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U transformers==\"4.38.2\"\n",
    "!pip install -q accelerate\n",
    "!pip install -q -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip install -q -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154ebbbe-0f1d-4ac6-99bf-c47910ccbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U git+https://github.com/huggingface/trl\n",
    "!pip install -q -U git+https://github.com/huggingface/peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28bed69-3bed-4bee-ba3a-8280ca785c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20ccfbd-ae10-4ef8-958e-7f2dcc89b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661b6c58-5501-4856-bb29-05b2cd32fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 09:09:45.769994: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-13 09:09:45.824889: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 09:09:46.652812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "import bitsandbytes as bnb\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13aa9266-325f-47b6-ac6c-f77ea89e476a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4c95ccf5ba4b8ca4118916a45b6eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-7b\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "max_seq_length = 2048\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)\n",
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70654ae4-e16b-413d-8841-5cb399460b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = ['positive', 'neutral', 'negative']\n",
    "    mapping = {'positive': 2, 'neutral': 1, 'none':1, 'negative': 0}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2f2b16b-5c27-4b27-ae00-649454b2a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        prompt = X_test.iloc[i][\"review\"]\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(**input_ids, max_new_tokens=1, temperature=0.0)\n",
    "        result = tokenizer.decode(outputs[0])\n",
    "        answer = result.split(\"=\")[-1].lower()\n",
    "        if \"positive\" in answer:\n",
    "            y_pred.append(\"positive\")\n",
    "        elif \"negative\" in answer:\n",
    "            y_pred.append(\"negative\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90a155a0-f3f4-4748-8b4d-0cb97bea75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 500/500 [01:06<00:00,  7.48it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b86043f8-34f3-49de-b7a9-0ac6020f7b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.686\n",
      "Accuracy for label 0: 0.684\n",
      "Accuracy for label 2: 0.688\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81       250\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.99      0.69      0.81       250\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.66      0.46      0.54       500\n",
      "weighted avg       0.99      0.69      0.81       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[171  77   2]\n",
      " [  0   0   0]\n",
      " [  2  76 172]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c81187bd-b8ca-4902-994a-3c8136916eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b734e9c02d2f4a4690df2291b840f97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b913ad2004f4d5c9c0246083b9e889a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"logs\",\n",
    "    num_train_epochs=5,\n",
    "    gradient_checkpointing=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=False,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps = 112,\n",
    "    eval_accumulation_steps=1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"review\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5274b2dc-65fb-41bc-88e7-e2ad8b93f518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 1:04:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>2.149400</td>\n",
       "      <td>2.707336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>1.877200</td>\n",
       "      <td>2.904984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>1.328200</td>\n",
       "      <td>3.121329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>3.566134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.551800</td>\n",
       "      <td>3.772694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Save trained model\n",
    "trainer.model.save_pretrained(\"trained-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bf53e8e-ed1b-4989-ac57-6594c68f893c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/500 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 500/500 [01:56<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.982\n",
      "Accuracy for label 0: 0.980\n",
      "Accuracy for label 2: 0.984\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       250\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.98      0.98      0.98       250\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.66      0.65      0.66       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245   1   4]\n",
      " [  0   0   0]\n",
      " [  4   0 246]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11ff9ac2-a724-4b2b-b221-c4952aa12d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'text': X_test[\"review\"], \n",
    "                           'y_true':y_true, \n",
    "                           'y_pred': y_pred},\n",
    "                         )\n",
    "evaluation.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fa413fd-96dc-4f5f-847d-69e0a16593b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13886</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48027</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19536</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27232</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28001</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36289</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9152</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14833</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41904</th>\n",
       "      <td>Analyze the sentiment of the news headline enc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    y_true    y_pred\n",
       "13886  Analyze the sentiment of the news headline enc...  positive  positive\n",
       "48027  Analyze the sentiment of the news headline enc...  positive  positive\n",
       "19536  Analyze the sentiment of the news headline enc...  positive  positive\n",
       "27232  Analyze the sentiment of the news headline enc...  positive  positive\n",
       "28001  Analyze the sentiment of the news headline enc...  positive  positive\n",
       "...                                                  ...       ...       ...\n",
       "36289  Analyze the sentiment of the news headline enc...  negative  negative\n",
       "2926   Analyze the sentiment of the news headline enc...  negative  negative\n",
       "9152   Analyze the sentiment of the news headline enc...  negative  negative\n",
       "14833  Analyze the sentiment of the news headline enc...  negative  negative\n",
       "41904  Analyze the sentiment of the news headline enc...  negative  negative\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c10396-24f9-4fcd-b7e0-2782248e27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(evaluation['y_true'].values.tolist(), evaluation['y_pred'].values.tolist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
